# Learn Impedance



##### SoftMimic

[link](https://arxiv.org/abs/2510.17792); leverage an inverse kinematics solver to generate an augmented dataset of feasible compliant motions, which they use to train an RL policy; Policy observes user input stiffness, original human motion demo, and sensor data, but it is rewarded with matching the augmented target generated by the inverse kinematics solver 

- Compliant motion tracking: minimize the difference between current posture and desired posture, as well as the desired compliant target pose (computed using a stiffness) 
- IK solver: An non-linear optimization solver that optimize several objectives



##### Variable Impedance Control

[link](https://www.roboticsproceedings.org/rss06/p20.pdf); Path Integral is a concept in quantum physics, robotics use it to sample trajectories and choose the weighted average of all the sampled trajectories as the optimal solution; For their method, Policy Improvement with Path Integral, they use DMP to represents the policy and update DMP parameters by the cost of each trajectory produced by DMP. And they use basis function to represent the scheduling of PD gains in the PD controller, to generate different variable impedance.

- Their impedance are just determined by the PD gains, not depending on external forces.

 

##### CHIP

[link](https://arxiv.org/abs/2512.14689); Locomotion, basically still learning a policy to track the demo motion, but add compliance; train a policy to train the humanoid robot's two hands and its head to track 3 goal points; while training, apply external forces to the three parts, and compute a "hindsight" goal which is on the **opposite** direction of the force, g_h = g_o - (1 / k) * f, k is the compliance coefficient, and f is the force, hence the "hindsight" goal is for fighting against the force, and the "hindsight" goal is inputed into the policy, therefore tracking the original goal is rewarded during training to let the policy learn to be compliant

- No force observation (compliance might be inferred based on history robot states, which is part of the policy observation)
